# ü§ñ Genesys Integration

**Integra√ß√£o da Genesys (LLaMA 70B) como Agente Master no Agent-MCP**

## üìÅ Estrutura dos Arquivos

```
genesys_integration/
‚îú‚îÄ‚îÄ genesys_agent.py         # ü§ñ Agente Genesys principal
‚îú‚îÄ‚îÄ genesys_server.py        # üñ•Ô∏è Servidor local FastAPI
‚îú‚îÄ‚îÄ genesys_bridge.py        # üåâ Bridge MCP
‚îú‚îÄ‚îÄ requirements_genesys.txt # üì¶ Depend√™ncias
‚îú‚îÄ‚îÄ models/                  # üß† Modelos LLaMA (links/c√≥pias)
‚îú‚îÄ‚îÄ data/logs/              # üìä Logs e intera√ß√µes
‚îú‚îÄ‚îÄ tools/                  # üîß Ferramentas copiadas da Genesys
‚îî‚îÄ‚îÄ workspace/              # üíª √Årea de trabalho segura
```

## üîß Componentes

### **genesys_agent.py**

- **Classe Principal**: `GenesysAgent`
- **Funcionalidades**:
  - Carregamento do modelo LLaMA 70B
  - Processamento de tarefas com contexto
  - Integra√ß√£o com ferramentas ReAct
  - Processamento multimodal (texto + imagem)
  - Status e monitoramento

### **genesys_server.py**

- **Framework**: FastAPI + Uvicorn
- **Endpoints**:
  - `/`: Status b√°sico
  - `/health`: Verifica√ß√£o de sa√∫de
  - `/status`: Status detalhado
  - `/chat`: Chat principal
  - `/multimodal`: Processamento imagem+texto
  - `/v1/chat/completions`: Compatibilidade OpenAI/Continue
  - `/reload-model`: Recarregamento do modelo

### **genesys_bridge.py**

- **Framework**: FastMCP (MCP Server)
- **Ferramentas MCP**:
  - `genesys_chat`: Chat direto
  - `genesys_multimodal`: Processamento multimodal
  - `genesys_status`: Status do sistema
  - `create_genesys_agent`: Criar agentes especializados
  - `assign_task_to_genesys_agent`: Atribuir tarefas
  - `list_genesys_agents`: Listar agentes
  - `terminate_genesys_agent`: Encerrar agentes

## üöÄ Como Executar

### **M√©todo 1: Sistema Integrado (Recomendado)**

```bash
# Do diret√≥rio raiz do Agent-MCP
python start_integrated.py
```

### **M√©todo 2: Componentes Individuais**

**Servidor Genesys:**

```bash
python -m genesys_integration.genesys_server
# Acesso: http://127.0.0.1:8002
```

**Bridge MCP:**

```bash
python -m genesys_integration.genesys_bridge
# Executa como servidor MCP stdio
```

**Teste do Agente:**

```bash
python genesys_integration/genesys_agent.py
# Teste b√°sico das funcionalidades
```

## üìã Configura√ß√£o

### **Vari√°veis de Ambiente (.env)**

```bash
# Modelo
MODEL_GGUF_FILENAME=llama-3-70b-instruct.Q4_K_M.gguf

# GPU
USE_GPU=true
N_GPU_LAYERS=-1

# Rede
GENESYS_LOCAL_HOST=127.0.0.1
GENESYS_LOCAL_PORT=8002

# Performance
MAX_CONTEXT_LENGTH=4096
BATCH_SIZE=512
TEMPERATURE=0.7
```

### **Depend√™ncias**

```bash
pip install -r requirements_genesys.txt
```

## üõ†Ô∏è Desenvolvimento

### **Adicionar Nova Ferramenta**

1. Implemente na Genesys original
2. Copie para `tools/`
3. Integre em `genesys_agent.py` no m√©todo `_setup_tools()`
4. Adicione endpoint em `genesys_server.py` se necess√°rio
5. Exponha via MCP em `genesys_bridge.py`

### **Exemplo de Nova Ferramenta MCP**

```python
# Em genesys_bridge.py
@mcp.tool()
async def nova_ferramenta(param: str) -> str:
    """
    Nova funcionalidade da Genesys
    """
    data = {"prompt": f"Execute nova ferramenta: {param}"}
    result = await bridge.call_genesys("/chat", data)
    return result.get("response", "Erro")
```

### **Debug e Logs**

```python
# Ativar logs detalhados
import logging
logging.basicConfig(level=logging.DEBUG)

# Teste individual de componentes
from genesys_integration.genesys_agent import genesys_agent
await genesys_agent.load_model()
response = await genesys_agent.process_task("Teste")
```

## üìä APIs Dispon√≠veis

### **REST API (FastAPI)**

```bash
# Status
GET http://127.0.0.1:8002/status

# Chat
POST http://127.0.0.1:8002/chat
{
  "prompt": "Sua pergunta",
  "context": {"key": "value"},
  "use_tools": true
}

# Multimodal
POST http://127.0.0.1:8002/multimodal
{
  "prompt": "Analise esta imagem",
  "image_data": "base64_encoded_image"
}
```

### **MCP Tools (via Agent-MCP)**

```javascript
// No dashboard Agent-MCP
genesys_chat({
  prompt: "Analise este c√≥digo Python",
  context: "{'language': 'python'}",
  use_tools: true,
});
```

## üîß Manuten√ß√£o

### **Atualizar Modelo**

1. Baixe novo modelo GGUF
2. Coloque em `models/`
3. Atualize `MODEL_GGUF_FILENAME` no `.env`
4. Reinicie: `/reload-model` ou restart completo

### **Monitorar Performance**

```bash
# Status da GPU
nvidia-smi

# Logs do servidor
tail -f data/logs/genesys.log

# Monitoramento do processo
top -p $(pgrep -f genesys_server)
```

### **Backup e Restore**

```bash
# Backup dos logs de intera√ß√£o (para fine-tuning)
tar -czf backup_$(date +%Y%m%d).tar.gz data/logs/

# Backup da configura√ß√£o
cp .env config_backup.env
```

## üö® Troubleshooting

### **Modelo n√£o carrega**

```bash
# Verificar arquivo
ls -la models/*.gguf

# Verificar mem√≥ria
free -h

# Logs detalhados
python genesys_integration/genesys_agent.py
```

### **GPU n√£o detectada**

```bash
# Verificar CUDA
nvidia-smi
nvcc --version

# Verificar PyTorch
python -c "import torch; print(torch.cuda.is_available())"

# Reinstalar llama-cpp-python com CUDA
pip uninstall llama-cpp-python
CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python
```

### **Servidor n√£o responde**

```bash
# Verificar porta
netstat -tlnp | grep 8002

# Teste direto
curl http://127.0.0.1:8002/health

# Logs de erro
python -m genesys_integration.genesys_server --debug
```

## üìà Performance

### **Otimiza√ß√µes Implementadas**

- **GPU Layers**: `-1` (todas as camadas na GPU)
- **Batch Size**: `512` (otimizado para performance)
- **Context Length**: `4096` (equilibrio mem√≥ria/capacidade)
- **Async Processing**: FastAPI + asyncio
- **Model Caching**: Modelo permanece carregado

### **Benchmarks Esperados**

- **CPU Only**: 1-5 tokens/segundo ‚ùå
- **GPU (RTX 3060)**: 15-30 tokens/segundo ‚úÖ
- **GPU (RTX 4090)**: 50-150 tokens/segundo üöÄ
- **Memory Usage**: 8-12GB VRAM para 70B Q4

## üîÆ Roadmap

### **Implementado ‚úÖ**

- [x] Integra√ß√£o b√°sica com Agent-MCP
- [x] Servidor FastAPI com hot-reload
- [x] Bridge MCP com ferramentas completas
- [x] Processamento multimodal
- [x] Sistema de logging para fine-tuning

### **Em Desenvolvimento üöß**

- [ ] Cache inteligente de respostas
- [ ] Load balancing para m√∫ltiplas GPUs
- [ ] Integra√ß√£o com Hugging Face Hub
- [ ] Auto-scaling baseado na demanda

### **Planejado üìã**

- [ ] Suporte para modelos quantizados GPTQ
- [ ] Integra√ß√£o com TensorRT para inference
- [ ] Distributed inference (m√∫ltiplas m√°quinas)
- [ ] Fine-tuning autom√°tico baseado em uso

---

**üéØ Esta integra√ß√£o transforma sua Genesys em um agente master ultra-eficiente dentro do ecossistema Agent-MCP!**
